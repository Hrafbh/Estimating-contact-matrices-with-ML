{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des bibliothéques\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\dataset_contact_all.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "train_data_all=train_data_all.to_numpy() #transfomer la data from dataframe to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_home=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\dataset_contact_home.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "train_data_home=train_data_home.to_numpy() #transfomer la data from dataframe to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_others=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\dataset_contact_others.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "train_data_others=train_data_others.to_numpy() #transfomer la data from dataframe to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_school=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\dataset_contact_school.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "train_data_school=train_data_school.to_numpy() #transfomer la data from dataframe to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_work=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\dataset_contact_work.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "train_data_work=train_data_work.to_numpy() #transfomer la data from dataframe to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.50738945  3.50749904  3.50745356 ...  3.50735007  3.50734013\n",
      "   3.50737145]\n",
      " [ 2.96153078  3.23309847  3.07626903 ...  2.83341004  2.81759605\n",
      "   2.88372902]\n",
      " [ 0.28279201  0.62147141  0.28672269 ... -0.054153   -0.09039011\n",
      "  -0.02613343]\n",
      " ...\n",
      " [-0.45530458 -0.45530458 -0.45530458 ... -0.45530458 -0.45530458\n",
      "  -0.45530458]\n",
      " [-0.45530458 -0.45530458 -0.45530458 ... -0.45530458 -0.45530458\n",
      "  -0.45530458]\n",
      " [-0.45530458 -0.45530458 -0.45530458 ... -0.45530458 -0.45530458\n",
      "  -0.45530458]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set_x_orig_all=np.zeros((30,512))\n",
    "\n",
    "X_test_all=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\input_seri_all.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "X_test_all=X_test_all.to_numpy()\n",
    "\n",
    "for i in range (30):\n",
    "    for j in range(1,513):\n",
    "                test_set_x_orig_all[i][j-1]=X_test_all[i][j]\n",
    "    \n",
    "test_set_x_orig_all=np.transpose(test_set_x_orig_all) \n",
    "m=np.mean(test_set_x_orig_all) #moyenne\n",
    "v=np.std(test_set_x_orig_all) #écart type\n",
    "test_set_x_orig_all=(test_set_x_orig_all-m)/v # centralize, strandarize the data\n",
    "print(test_set_x_orig_all) # test_set_x_orig est un array de taille (512,1) , 512=64*r , pour chaque catégorie d'age , il'ya les valeurs de S,E,I,R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.66900344  2.66900294  2.66900352 ...  2.66900316  2.66900319\n",
      "   2.66900348]\n",
      " [ 2.66882262  2.66865565  2.66884469 ...  2.66873963  2.66875637\n",
      "   2.66884353]\n",
      " [ 2.64807825  2.61393854  2.6518701  ...  2.63234841  2.63592062\n",
      "   2.65202278]\n",
      " ...\n",
      " [-0.50026157 -0.50026128 -0.50026167 ... -0.50026156 -0.50026161\n",
      "  -0.50026184]\n",
      " [-0.50026117 -0.50026116 -0.50026117 ... -0.50026117 -0.50026117\n",
      "  -0.50026118]\n",
      " [-0.50026116 -0.50026116 -0.50026116 ... -0.50026116 -0.50026116\n",
      "  -0.50026116]]\n"
     ]
    }
   ],
   "source": [
    "test_set_x_orig_home=np.zeros((30,512))\n",
    "\n",
    "X_test_home=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\input_seri_home.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "X_test_home=X_test_home.to_numpy()\n",
    "\n",
    "for i in range (30):\n",
    "    for j in range(1,513):\n",
    "                test_set_x_orig_home[i][j-1]=X_test_home[i][j]\n",
    "    \n",
    "test_set_x_orig_home=np.transpose(test_set_x_orig_home) \n",
    "m=np.mean(test_set_x_orig_home) #moyenne\n",
    "v=np.std(test_set_x_orig_home) #écart type\n",
    "test_set_x_orig_home=(test_set_x_orig_home-m)/v # centralize, strandarize the data\n",
    "print(test_set_x_orig_home) # test_set_x_orig est un array de taille (512,1) , 512=64*r , pour chaque catégorie d'age , il'ya les valeurs de S,E,I,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.54523925  2.54523929  2.54523914 ...  2.5452387   2.54523861\n",
      "   2.54523863]\n",
      " [ 2.54520982  2.54523373  2.54521544 ...  2.54513327  2.54514031\n",
      "   2.54516317]\n",
      " [ 2.54061804  2.54497742  2.54326468 ...  2.53080833  2.53388292\n",
      "   2.53827345]\n",
      " ...\n",
      " [-0.51888912 -0.51890606 -0.51888744 ... -0.51888467 -0.51888609\n",
      "  -0.51888608]\n",
      " [-0.51888239 -0.51888227 -0.51888112 ... -0.51888103 -0.5188811\n",
      "  -0.51888104]\n",
      " [-0.51888117 -0.5188809  -0.51888086 ... -0.51888086 -0.51888086\n",
      "  -0.51888085]]\n"
     ]
    }
   ],
   "source": [
    "test_set_x_orig_others=np.zeros((30,512))\n",
    "\n",
    "X_test_others=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\input_seri_others.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "X_test_others=X_test_others.to_numpy()\n",
    "\n",
    "for i in range (30):\n",
    "    for j in range(1,513):\n",
    "                test_set_x_orig_others[i][j-1]=X_test_others[i][j]\n",
    "    \n",
    "test_set_x_orig_others=np.transpose(test_set_x_orig_others) \n",
    "m=np.mean(test_set_x_orig_others) #moyenne\n",
    "v=np.std(test_set_x_orig_others) #écart type\n",
    "test_set_x_orig_others=(test_set_x_orig_others-m)/v # centralize, strandarize the data\n",
    "print(test_set_x_orig_others) # test_set_x_orig est un array de taille (512,1) , 512=64*r , pour chaque catégorie d'age , il'ya les valeurs de S,E,I,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.73205123  1.73205123  1.73205123 ...  1.73205123  1.73205123\n",
      "   1.73205123]\n",
      " [ 1.73205123  1.73205123  1.73205123 ...  1.73205123  1.73205123\n",
      "   1.73205123]\n",
      " [ 1.73205123  1.73205123  1.73205123 ...  1.73205123  1.73205123\n",
      "   1.73205123]\n",
      " ...\n",
      " [-0.57735027 -0.57735027 -0.57735027 ... -0.57735027 -0.57735027\n",
      "  -0.57735027]\n",
      " [-0.57735027 -0.57735027 -0.57735027 ... -0.57735027 -0.57735027\n",
      "  -0.57735027]\n",
      " [-0.57735027 -0.57735027 -0.57735027 ... -0.57735027 -0.57735027\n",
      "  -0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "test_set_x_orig_school=np.zeros((30,512))\n",
    "\n",
    "X_test_school=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\input_seri_school.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "X_test_school=X_test_school.to_numpy()\n",
    "\n",
    "for i in range (30):\n",
    "    for j in range(1,513):\n",
    "                test_set_x_orig_school[i][j-1]=X_test_school[i][j]\n",
    "    \n",
    "test_set_x_orig_school=np.transpose(test_set_x_orig_school) \n",
    "m=np.mean(test_set_x_orig_school) #moyenne\n",
    "v=np.std(test_set_x_orig_school) #écart type\n",
    "test_set_x_orig_school=(test_set_x_orig_school-m)/v # centralize, strandarize the data\n",
    "print(test_set_x_orig_school) # test_set_x_orig est un array de taille (512,1) , 512=64*r , pour chaque catégorie d'age , il'ya les valeurs de S,E,I,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.45411089  2.45411102  2.45411086 ...  2.45411084  2.45411076\n",
      "   2.45411075]\n",
      " [ 2.45409479  2.45410754  2.45409065 ...  2.45408672  2.45407177\n",
      "   2.45406983]\n",
      " [ 2.4531217   2.45401667  2.45271012 ...  2.45227604  2.45034757\n",
      "   2.45002952]\n",
      " ...\n",
      " [-0.54881229 -0.54890205 -0.54880521 ... -0.54880156 -0.54878439\n",
      "  -0.54877986]\n",
      " [-0.54878065 -0.54884135 -0.54877653 ... -0.548777   -0.54876392\n",
      "  -0.54875822]\n",
      " [-0.54876847 -0.54881025 -0.54876473 ... -0.54876737 -0.54875546\n",
      "  -0.54874869]]\n"
     ]
    }
   ],
   "source": [
    "test_set_x_orig_work=np.zeros((30,512))\n",
    "\n",
    "X_test_work=pd.read_excel(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\input_seri_work.xlsx\")#Rq:génerer le dataset avec le programme dataset.py pour charger le dataset\n",
    "X_test_work=X_test_work.to_numpy()\n",
    "\n",
    "for i in range (30):\n",
    "    for j in range(1,513):\n",
    "                test_set_x_orig_work[i][j-1]=X_test_work[i][j]\n",
    "    \n",
    "test_set_x_orig_work=np.transpose(test_set_x_orig_work) \n",
    "m=np.mean(test_set_x_orig_work) #moyenne\n",
    "v=np.std(test_set_x_orig_work) #écart type\n",
    "test_set_x_orig_work=(test_set_x_orig_work-m)/v # centralize, strandarize the data\n",
    "print(test_set_x_orig_work) # test_set_x_orig est un array de taille (512,1) , 512=64*r , pour chaque catégorie d'age , il'ya les valeurs de S,E,I,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "# importation de la data d'entrenement , on va entrainer notre modele avec 32 instances\n",
    "train_set_x_orig_all=np.zeros((120,64*r))\n",
    "for i in range(120):\n",
    "    for j in range(1,64*r+1):\n",
    "        train_set_x_orig_all[i][j-1]=train_data_all[i][j]\n",
    "train_set_x_orig_all=np.transpose(train_set_x_orig_all)          \n",
    "m=np.mean(train_set_x_orig_all) #moyenne\n",
    "v=np.std(train_set_x_orig_all) #écart type\n",
    "train_set_x_orig_all=(train_set_x_orig_all-m)/v # centralize, strandarize the data\n",
    "#train_set_x_orig=(train_set_x_orig)/np.max(train_set_x_orig)\n",
    "print(np.shape(train_set_x_orig_all)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "# importation de la data d'entrenement , on va entrainer notre modele avec 32 instances\n",
    "train_set_x_orig_home=np.zeros((120,64*r))\n",
    "for i in range(120):\n",
    "    for j in range(1,64*r+1):\n",
    "        train_set_x_orig_home[i][j-1]=train_data_home[i][j]\n",
    "train_set_x_orig_home=np.transpose(train_set_x_orig_home)          \n",
    "m=np.mean(train_set_x_orig_home) #moyenne\n",
    "v=np.std(train_set_x_orig_home) #écart type\n",
    "train_set_x_orig_home=(train_set_x_orig_home-m)/v # centralize, strandarize the data\n",
    "#train_set_x_orig=(train_set_x_orig)/np.max(train_set_x_orig)\n",
    "print(np.shape(train_set_x_orig_home)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "# importation de la data d'entrenement , on va entrainer notre modele avec 32 instances\n",
    "train_set_x_orig_others=np.zeros((120,64*r))\n",
    "for i in range(120):\n",
    "    for j in range(1,64*r+1):\n",
    "        train_set_x_orig_others[i][j-1]=train_data_others[i][j]\n",
    "train_set_x_orig_others=np.transpose(train_set_x_orig_others)          \n",
    "m=np.mean(train_set_x_orig_others) #moyenne\n",
    "v=np.std(train_set_x_orig_others) #écart type\n",
    "train_set_x_orig_others=(train_set_x_orig_others-m)/v # centralize, strandarize the data\n",
    "#train_set_x_orig=(train_set_x_orig)/np.max(train_set_x_orig)\n",
    "print(np.shape(train_set_x_orig_others)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "# importation de la data d'entrenement , on va entrainer notre modele avec 32 instances\n",
    "train_set_x_orig_school=np.zeros((120,64*r))\n",
    "for i in range(120):\n",
    "    for j in range(1,64*r+1):\n",
    "        train_set_x_orig_school[i][j-1]=train_data_school[i][j]\n",
    "train_set_x_orig_school=np.transpose(train_set_x_orig_school)          \n",
    "m=np.mean(train_set_x_orig_school) #moyenne\n",
    "v=np.std(train_set_x_orig_school) #écart type\n",
    "train_set_x_orig_school=(train_set_x_orig_school-m)/v # centralize, strandarize the data\n",
    "#train_set_x_orig=(train_set_x_orig)/np.max(train_set_x_orig)\n",
    "print(np.shape(train_set_x_orig_school)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "# importation de la data d'entrenement , on va entrainer notre modele avec 32 instances\n",
    "train_set_x_orig_work=np.zeros((120,64*r))\n",
    "for i in range(120):\n",
    "    for j in range(1,64*r+1):\n",
    "        train_set_x_orig_work[i][j-1]=train_data_work[i][j]\n",
    "train_set_x_orig_work=np.transpose(train_set_x_orig_work)          \n",
    "m=np.mean(train_set_x_orig_work) #moyenne\n",
    "v=np.std(train_set_x_orig_work) #écart type\n",
    "train_set_x_orig_work=(train_set_x_orig_work-m)/v # centralize, strandarize the data\n",
    "#train_set_x_orig=(train_set_x_orig)/np.max(train_set_x_orig)\n",
    "print(np.shape(train_set_x_orig_work)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "#importation des output(valeurs de contact) de la data d'entrainement\n",
    "train_set_y_m_all=np.zeros((120,256))\n",
    "for i in range(120):\n",
    "    for j in range(1,257):\n",
    "        train_set_y_m_all[i][j-1]=train_data_all[i][j+(r*64)]\n",
    "\n",
    "train_set_y_m_all=np.transpose(train_set_y_m_all)    \n",
    "#m=np.mean(train_set_y) #moyenne\n",
    "#v=np.std(train_set_y) #écart type\n",
    "#train_set_y=(train_set_y-m)/v   # centralize, strandarize the data\n",
    "train_set_y_all=train_set_y_m_all/np.max(train_set_y_m_all)\n",
    "print(np.shape(train_set_y_all)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "#importation des output(valeurs de contact) de la data d'entrainement\n",
    "train_set_y_m_home=np.zeros((120,256))\n",
    "for i in range(120):\n",
    "    for j in range(1,257):\n",
    "        train_set_y_m_home[i][j-1]=train_data_home[i][j+(r*64)]\n",
    "\n",
    "train_set_y_m_home=np.transpose(train_set_y_m_home)    \n",
    "#m=np.mean(train_set_y) #moyenne\n",
    "#v=np.std(train_set_y) #écart type\n",
    "#train_set_y=(train_set_y-m)/v   # centralize, strandarize the data\n",
    "train_set_y_home=train_set_y_m_home/np.max(train_set_y_m_home)\n",
    "print(np.shape(train_set_y_home)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "#importation des output(valeurs de contact) de la data d'entrainement\n",
    "train_set_y_m_others=np.zeros((120,256))\n",
    "for i in range(120):\n",
    "    for j in range(1,257):\n",
    "        train_set_y_m_others[i][j-1]=train_data_others[i][j+(r*64)]\n",
    "\n",
    "train_set_y_m_others=np.transpose(train_set_y_m_others)    \n",
    "#m=np.mean(train_set_y) #moyenne\n",
    "#v=np.std(train_set_y) #écart type\n",
    "#train_set_y=(train_set_y-m)/v   # centralize, strandarize the data\n",
    "train_set_y_others=train_set_y_m_others/np.max(train_set_y_m_others)\n",
    "print(np.shape(train_set_y_others)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "#importation des output(valeurs de contact) de la data d'entrainement\n",
    "train_set_y_m_school=np.zeros((120,256))\n",
    "for i in range(120):\n",
    "    for j in range(1,257):\n",
    "        train_set_y_m_school[i][j-1]=train_data_school[i][j+(r*64)]\n",
    "\n",
    "train_set_y_m_school=np.transpose(train_set_y_m_school)    \n",
    "#m=np.mean(train_set_y) #moyenne\n",
    "#v=np.std(train_set_y) #écart type\n",
    "#train_set_y=(train_set_y-m)/v   # centralize, strandarize the data\n",
    "train_set_y_school=train_set_y_m_school/np.max(train_set_y_m_school)\n",
    "print(np.shape(train_set_y_school)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 120)\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "#importation des output(valeurs de contact) de la data d'entrainement\n",
    "train_set_y_m_work=np.zeros((120,256))\n",
    "for i in range(120):\n",
    "    for j in range(1,257):\n",
    "        train_set_y_m_work[i][j-1]=train_data_work[i][j+(r*64)]\n",
    "\n",
    "train_set_y_m_work=np.transpose(train_set_y_m_work)    \n",
    "#m=np.mean(train_set_y) #moyenne\n",
    "#v=np.std(train_set_y) #écart type\n",
    "#train_set_y=(train_set_y-m)/v   # centralize, strandarize the data\n",
    "train_set_y_work=train_set_y_m_work/np.max(train_set_y_m_work)\n",
    "print(np.shape(train_set_y_work)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s=1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "r=8\n",
    "#initialisation des vecteurs w et b pour la regression , w est un vecteur de taille (64,1)\n",
    "def initialize_with_zeros(dim):\n",
    "    w=np.zeros((dim,256),dtype=float)\n",
    "    b= np.zeros((256,1),dtype=float)\n",
    "    return w, b\n",
    "w,b=initialize_with_zeros(64*r)\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.588830833596724\n"
     ]
    }
   ],
   "source": [
    "#les étapes de propagation \"forward\" et \"backward\" pour l'apprentissage des paramètres.\n",
    "def propagate(w, b, X, Y):\n",
    "    r=8\n",
    "    m = 64*r\n",
    "    A=sigmoid(np.dot(w.T,X)+b)\n",
    "    #la fonction coût et son gradient pour la propagation \n",
    "    #negative log-likelihood cost for logistic regression\n",
    "    cost=-(1/m)*(np.sum(Y*np.log(A)+(1-Y)*np.log(1-A)))\n",
    "    #gradient of the loss par rapport w\n",
    "    dw=(1/m)*np.dot(X,(A-Y).T)\n",
    "    #gradient of the loss par rapport b\n",
    "    db=(1/m)*np.sum(A-Y)\n",
    "    \n",
    "    cost = np.squeeze(np.array(cost))\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "grads, cost=propagate(w, b, train_set_x_orig_all, train_set_y_all)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': array([[-0.02519511, -0.02513885, -0.02486295, ..., -0.01901138,\n",
      "        -0.02162788, -0.02024437],\n",
      "       [-0.02226889, -0.02235254, -0.02195046, ..., -0.0083663 ,\n",
      "        -0.01459752, -0.01165323],\n",
      "       [-0.00316279, -0.0033877 , -0.00343997, ...,  0.01214054,\n",
      "         0.00478256,  0.00806225],\n",
      "       ...,\n",
      "       [ 0.00328018,  0.00327284,  0.003237  , ...,  0.00247585,\n",
      "         0.00281621,  0.0026363 ],\n",
      "       [ 0.00328018,  0.00327284,  0.003237  , ...,  0.00247585,\n",
      "         0.00281621,  0.0026363 ],\n",
      "       [ 0.00328018,  0.00327284,  0.003237  , ...,  0.00247585,\n",
      "         0.00281621,  0.0026363 ]]), 'b': array([[-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151],\n",
      "       [-1.10058151]])}\n"
     ]
    }
   ],
   "source": [
    "#Cette fonction optimise w et b en exécutant l'algorithme gradient descente\n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)\n",
    "    \n",
    "    costs = []\n",
    "    L=[]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "\n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "\n",
    "        w = w -learning_rate*dw\n",
    "        b = b -learning_rate*db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            # Print the cost every 100 training iterations\n",
    "            if print_cost:\n",
    "                print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs \n",
    "\n",
    "# params -- dictionnaire contenant les vecteurs w et  b\n",
    "# grads -- dictionnaire contenant les gradients de la fonction de coût par rapport à w et b\n",
    "# costs -- liste de tous les coûts calculés pendant l'optimisation,\n",
    "\n",
    "params, grads, costs =optimize(w, b, train_set_x_orig_all, train_set_y_all, num_iterations=2000, learning_rate=0.009, print_cost=False)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00784668, 0.00776747, 0.00871559, ..., 0.00883995, 0.00841069,\n",
       "        0.00876429],\n",
       "       [0.00781603, 0.00773545, 0.00873103, ..., 0.00885845, 0.00841333,\n",
       "        0.00878069],\n",
       "       [0.00824498, 0.00816328, 0.00918004, ..., 0.0093099 , 0.00885463,\n",
       "        0.00923039],\n",
       "       ...,\n",
       "       [0.03333681, 0.03311437, 0.0269079 , ..., 0.02680322, 0.02846688,\n",
       "        0.02695722],\n",
       "       [0.01764206, 0.01750235, 0.01657402, ..., 0.0166492 , 0.01678726,\n",
       "        0.01663194],\n",
       "       [0.02412274, 0.02395541, 0.02118673, ..., 0.02120111, 0.02187325,\n",
       "        0.02124268]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fonction pour prédire la valeur de contact en utilsant les vecteurs w et b entrainées\n",
    "def predict(w, b, X):\n",
    "\n",
    "    A=sigmoid(np.dot(w.T,X)+b)\n",
    "\n",
    "    return A\n",
    "\n",
    "predict(params['w'],params['b'],train_set_x_orig_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construction du model en appllant les fonctions implémentées précedement\n",
    "def model(X_train, Y_train, X_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    r=8\n",
    "    dim = 64*r\n",
    "    w,b=initialize_with_zeros(dim) \n",
    "\n",
    "    params, grads, cost = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    if print_cost:\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        #print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "    d = {\"costs\": cost,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 41.588831\n",
      "Cost after iteration 100: 10.360941\n",
      "Cost after iteration 200: 10.354911\n",
      "Cost after iteration 300: 10.352281\n",
      "Cost after iteration 400: 10.350088\n",
      "Cost after iteration 500: 10.348135\n",
      "Cost after iteration 600: 10.346373\n",
      "Cost after iteration 700: 10.344772\n",
      "Cost after iteration 800: 10.343308\n",
      "Cost after iteration 900: 10.341965\n",
      "Cost after iteration 1000: 10.340728\n",
      "Cost after iteration 1100: 10.339586\n",
      "Cost after iteration 1200: 10.338527\n",
      "Cost after iteration 1300: 10.337545\n",
      "Cost after iteration 1400: 10.336631\n",
      "Cost after iteration 1500: 10.335779\n",
      "Cost after iteration 1600: 10.334983\n",
      "Cost after iteration 1700: 10.334239\n",
      "Cost after iteration 1800: 10.333543\n",
      "Cost after iteration 1900: 10.332889\n",
      "Cost after iteration 2000: 10.332275\n",
      "Cost after iteration 2100: 10.331697\n",
      "Cost after iteration 2200: 10.331153\n",
      "Cost after iteration 2300: 10.330640\n",
      "Cost after iteration 2400: 10.330155\n",
      "Cost after iteration 2500: 10.329697\n",
      "Cost after iteration 2600: 10.329263\n",
      "Cost after iteration 2700: 10.328852\n",
      "Cost after iteration 2800: 10.328462\n",
      "Cost after iteration 2900: 10.328092\n",
      "Cost after iteration 3000: 10.327740\n",
      "Cost after iteration 3100: 10.327405\n",
      "Cost after iteration 3200: 10.327086\n",
      "Cost after iteration 3300: 10.326782\n",
      "Cost after iteration 3400: 10.326491\n",
      "Cost after iteration 3500: 10.326213\n",
      "Cost after iteration 3600: 10.325948\n",
      "Cost after iteration 3700: 10.325693\n",
      "Cost after iteration 3800: 10.325449\n",
      "Cost after iteration 3900: 10.325215\n",
      "Cost after iteration 4000: 10.324991\n",
      "Cost after iteration 4100: 10.324775\n",
      "Cost after iteration 4200: 10.324567\n",
      "Cost after iteration 4300: 10.324367\n",
      "Cost after iteration 4400: 10.324174\n",
      "Cost after iteration 4500: 10.323988\n",
      "Cost after iteration 4600: 10.323808\n",
      "Cost after iteration 4700: 10.323634\n",
      "Cost after iteration 4800: 10.323467\n",
      "Cost after iteration 4900: 10.323304\n",
      "Cost after iteration 5000: 10.323147\n",
      "Cost after iteration 5100: 10.322994\n",
      "Cost after iteration 5200: 10.322846\n",
      "Cost after iteration 5300: 10.322702\n",
      "Cost after iteration 5400: 10.322562\n",
      "Cost after iteration 5500: 10.322426\n",
      "Cost after iteration 5600: 10.322294\n",
      "Cost after iteration 5700: 10.322165\n",
      "Cost after iteration 5800: 10.322040\n",
      "Cost after iteration 5900: 10.321917\n",
      "Cost after iteration 6000: 10.321798\n",
      "Cost after iteration 6100: 10.321681\n",
      "Cost after iteration 6200: 10.321567\n",
      "Cost after iteration 6300: 10.321455\n",
      "Cost after iteration 6400: 10.321346\n",
      "Cost after iteration 6500: 10.321239\n",
      "Cost after iteration 6600: 10.321135\n",
      "Cost after iteration 6700: 10.321032\n",
      "Cost after iteration 6800: 10.320932\n",
      "Cost after iteration 6900: 10.320833\n",
      "Cost after iteration 7000: 10.320736\n",
      "Cost after iteration 7100: 10.320641\n",
      "Cost after iteration 7200: 10.320548\n",
      "Cost after iteration 7300: 10.320456\n",
      "Cost after iteration 7400: 10.320366\n",
      "Cost after iteration 7500: 10.320277\n",
      "Cost after iteration 7600: 10.320190\n",
      "Cost after iteration 7700: 10.320103\n",
      "Cost after iteration 7800: 10.320019\n",
      "Cost after iteration 7900: 10.319935\n",
      "Cost after iteration 8000: 10.319853\n",
      "Cost after iteration 8100: 10.319771\n",
      "Cost after iteration 8200: 10.319691\n",
      "Cost after iteration 8300: 10.319612\n",
      "Cost after iteration 8400: 10.319534\n",
      "Cost after iteration 8500: 10.319457\n",
      "Cost after iteration 8600: 10.319381\n",
      "Cost after iteration 8700: 10.319305\n",
      "Cost after iteration 8800: 10.319231\n",
      "Cost after iteration 8900: 10.319157\n",
      "Cost after iteration 9000: 10.319085\n",
      "Cost after iteration 9100: 10.319013\n",
      "Cost after iteration 9200: 10.318942\n",
      "Cost after iteration 9300: 10.318871\n",
      "Cost after iteration 9400: 10.318801\n",
      "Cost after iteration 9500: 10.318732\n",
      "Cost after iteration 9600: 10.318664\n",
      "Cost after iteration 9700: 10.318596\n",
      "Cost after iteration 9800: 10.318529\n",
      "Cost after iteration 9900: 10.318463\n",
      "train accuracy: 99.48401955380639 %\n",
      "{'costs': [array(41.58883083), array(10.36094117), array(10.35491097), array(10.35228065), array(10.35008797), array(10.34813545), array(10.34637324), array(10.34477154), array(10.34330801), array(10.34196498), array(10.34072811), array(10.33958554), array(10.33852728), array(10.33754482), array(10.33663083), array(10.3357789), array(10.33498344), array(10.33423946), array(10.33354257), array(10.33288882), array(10.33227467), array(10.33169695), array(10.33115278), array(10.33063958), array(10.33015497), array(10.32969682), array(10.32926317), array(10.32885225), array(10.32846242), array(10.3280922), array(10.32774021), array(10.3274052), array(10.32708602), array(10.3267816), array(10.32649097), array(10.32621321), array(10.32594751), array(10.32569307), array(10.32544919), array(10.32521521), array(10.32499052), array(10.32477453), array(10.32456673), array(10.32436663), array(10.32417376), array(10.3239877), array(10.32380805), array(10.32363445), array(10.32346655), array(10.32330402), array(10.32314658), array(10.32299392), array(10.3228458), array(10.32270197), array(10.3225622), array(10.32242626), array(10.32229397), array(10.32216513), array(10.32203956), array(10.3219171), array(10.32179759), array(10.32168089), array(10.32156684), array(10.32145534), array(10.32134625), array(10.32123945), array(10.32113485), array(10.32103233), array(10.32093181), array(10.32083319), array(10.32073639), array(10.32064132), array(10.32054791), array(10.32045609), array(10.32036579), array(10.32027695), array(10.3201895), array(10.3201034), array(10.32001857), array(10.31993498), array(10.31985258), array(10.31977131), array(10.31969114), array(10.31961202), array(10.31953392), array(10.3194568), array(10.31938061), array(10.31930534), array(10.31923095), array(10.3191574), array(10.31908467), array(10.31901273), array(10.31894156), array(10.31887113), array(10.31880141), array(10.31873239), array(10.31866404), array(10.31859635), array(10.31852929), array(10.31846285)], 'Y_prediction_test': array([[0.00894537, 0.00794249, 0.00838921, ..., 0.00909382, 0.00904626,\n",
      "        0.00879776],\n",
      "       [0.00900747, 0.00788622, 0.00840435, ..., 0.00919225, 0.00914129,\n",
      "        0.0088653 ],\n",
      "       [0.00942655, 0.00833311, 0.00884645, ..., 0.00962467, 0.00957594,\n",
      "        0.00930319],\n",
      "       ...,\n",
      "       [0.02430212, 0.03347725, 0.02607559, ..., 0.02019005, 0.02020909,\n",
      "        0.02196839],\n",
      "       [0.01553396, 0.01844847, 0.01594239, ..., 0.01387642, 0.01385909,\n",
      "        0.01448321],\n",
      "       [0.01941741, 0.02481228, 0.02038913, ..., 0.01679498, 0.0167929 ,\n",
      "        0.01786957]]), 'Y_prediction_train': array([[0.00774094, 0.00766823, 0.00876914, ..., 0.00889779, 0.00840669,\n",
      "        0.00881611],\n",
      "       [0.00761047, 0.00753078, 0.00882552, ..., 0.00896737, 0.00841131,\n",
      "        0.00887696],\n",
      "       [0.00806359, 0.00799127, 0.00927039, ..., 0.00940653, 0.00885618,\n",
      "        0.00931782],\n",
      "       ...,\n",
      "       [0.04359845, 0.04286001, 0.02261684, ..., 0.02209196, 0.02730844,\n",
      "        0.02264153],\n",
      "       [0.02186648, 0.02163524, 0.01475619, ..., 0.01459843, 0.01644644,\n",
      "        0.01478326],\n",
      "       [0.03086794, 0.03051794, 0.01830381, ..., 0.01799129, 0.02118145,\n",
      "        0.01832142]]), 'w': array([[-0.02515631, -0.02492507, -0.02497245, ..., -0.02324929,\n",
      "        -0.02472512, -0.02392154],\n",
      "       [-0.0232883 , -0.02358488, -0.02282938, ...,  0.00303739,\n",
      "        -0.00652686, -0.00178841],\n",
      "       [-0.00502728, -0.00590065, -0.00648939, ...,  0.03497345,\n",
      "         0.02135436,  0.02830786],\n",
      "       ...,\n",
      "       [ 0.00327486,  0.00324469,  0.0032513 , ...,  0.00302855,\n",
      "         0.0032203 ,  0.00311635],\n",
      "       [ 0.00327486,  0.00324469,  0.0032513 , ...,  0.00302855,\n",
      "         0.0032203 ,  0.00311635],\n",
      "       [ 0.00327486,  0.00324469,  0.0032513 , ...,  0.00302855,\n",
      "         0.0032203 ,  0.00311635]]), 'b': array([[-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911],\n",
      "       [-1.09636911]]), 'learning_rate': 0.01, 'num_iterations': 10000}\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_all = model(train_set_x_orig_all, train_set_y_all, test_set_x_orig_all, num_iterations=10000, learning_rate=0.01, print_cost=True)\n",
    "print(logistic_regression_model_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 41.588831\n",
      "Cost after iteration 100: 23.698907\n",
      "Cost after iteration 200: 23.676752\n",
      "Cost after iteration 300: 23.662612\n",
      "Cost after iteration 400: 23.652623\n",
      "Cost after iteration 500: 23.644902\n",
      "Cost after iteration 600: 23.638501\n",
      "Cost after iteration 700: 23.632922\n",
      "Cost after iteration 800: 23.627890\n",
      "Cost after iteration 900: 23.623251\n",
      "Cost after iteration 1000: 23.618910\n",
      "Cost after iteration 1100: 23.614809\n",
      "Cost after iteration 1200: 23.610909\n",
      "Cost after iteration 1300: 23.607184\n",
      "Cost after iteration 1400: 23.603615\n",
      "Cost after iteration 1500: 23.600185\n",
      "Cost after iteration 1600: 23.596885\n",
      "Cost after iteration 1700: 23.593703\n",
      "Cost after iteration 1800: 23.590631\n",
      "Cost after iteration 1900: 23.587663\n",
      "Cost after iteration 2000: 23.584793\n",
      "Cost after iteration 2100: 23.582013\n",
      "Cost after iteration 2200: 23.579319\n",
      "Cost after iteration 2300: 23.576707\n",
      "Cost after iteration 2400: 23.574172\n",
      "Cost after iteration 2500: 23.571709\n",
      "Cost after iteration 2600: 23.569315\n",
      "Cost after iteration 2700: 23.566987\n",
      "Cost after iteration 2800: 23.564722\n",
      "Cost after iteration 2900: 23.562515\n",
      "Cost after iteration 3000: 23.560364\n",
      "Cost after iteration 3100: 23.558267\n",
      "Cost after iteration 3200: 23.556222\n",
      "Cost after iteration 3300: 23.554224\n",
      "Cost after iteration 3400: 23.552273\n",
      "Cost after iteration 3500: 23.550367\n",
      "Cost after iteration 3600: 23.548502\n",
      "Cost after iteration 3700: 23.546678\n",
      "Cost after iteration 3800: 23.544893\n",
      "Cost after iteration 3900: 23.543144\n",
      "Cost after iteration 4000: 23.541431\n",
      "Cost after iteration 4100: 23.539752\n",
      "Cost after iteration 4200: 23.538105\n",
      "Cost after iteration 4300: 23.536489\n",
      "Cost after iteration 4400: 23.534903\n",
      "Cost after iteration 4500: 23.533346\n",
      "Cost after iteration 4600: 23.531817\n",
      "Cost after iteration 4700: 23.530314\n",
      "Cost after iteration 4800: 23.528836\n",
      "Cost after iteration 4900: 23.527384\n",
      "Cost after iteration 5000: 23.525954\n",
      "Cost after iteration 5100: 23.524548\n",
      "Cost after iteration 5200: 23.523163\n",
      "Cost after iteration 5300: 23.521800\n",
      "Cost after iteration 5400: 23.520457\n",
      "Cost after iteration 5500: 23.519135\n",
      "Cost after iteration 5600: 23.517831\n",
      "Cost after iteration 5700: 23.516545\n",
      "Cost after iteration 5800: 23.515278\n",
      "Cost after iteration 5900: 23.514028\n",
      "Cost after iteration 6000: 23.512795\n",
      "Cost after iteration 6100: 23.511578\n",
      "Cost after iteration 6200: 23.510377\n",
      "Cost after iteration 6300: 23.509191\n",
      "Cost after iteration 6400: 23.508020\n",
      "Cost after iteration 6500: 23.506864\n",
      "Cost after iteration 6600: 23.505722\n",
      "Cost after iteration 6700: 23.504593\n",
      "Cost after iteration 6800: 23.503478\n",
      "Cost after iteration 6900: 23.502375\n",
      "Cost after iteration 7000: 23.501286\n",
      "Cost after iteration 7100: 23.500208\n",
      "Cost after iteration 7200: 23.499143\n",
      "Cost after iteration 7300: 23.498090\n",
      "Cost after iteration 7400: 23.497047\n",
      "Cost after iteration 7500: 23.496016\n",
      "Cost after iteration 7600: 23.494996\n",
      "Cost after iteration 7700: 23.493987\n",
      "Cost after iteration 7800: 23.492988\n",
      "Cost after iteration 7900: 23.491999\n",
      "Cost after iteration 8000: 23.491020\n",
      "Cost after iteration 8100: 23.490051\n",
      "Cost after iteration 8200: 23.489092\n",
      "Cost after iteration 8300: 23.488142\n",
      "Cost after iteration 8400: 23.487201\n",
      "Cost after iteration 8500: 23.486269\n",
      "Cost after iteration 8600: 23.485346\n",
      "Cost after iteration 8700: 23.484431\n",
      "Cost after iteration 8800: 23.483525\n",
      "Cost after iteration 8900: 23.482628\n",
      "Cost after iteration 9000: 23.481739\n",
      "Cost after iteration 9100: 23.480857\n",
      "Cost after iteration 9200: 23.479984\n",
      "Cost after iteration 9300: 23.479119\n",
      "Cost after iteration 9400: 23.478261\n",
      "Cost after iteration 9500: 23.477411\n",
      "Cost after iteration 9600: 23.476568\n",
      "Cost after iteration 9700: 23.475732\n",
      "Cost after iteration 9800: 23.474904\n",
      "Cost after iteration 9900: 23.474082\n",
      "train accuracy: 98.04049634285242 %\n",
      "{'costs': [array(41.58883083), array(23.69890731), array(23.67675215), array(23.66261241), array(23.65262259), array(23.64490201), array(23.63850127), array(23.63292169), array(23.62789023), array(23.62325073), array(23.61890981), array(23.61480887), array(23.61090932), array(23.60718442), array(23.60361473), array(23.6001854), array(23.59688466), array(23.59370275), array(23.59063142), array(23.58766347), array(23.58479253), array(23.58201287), array(23.57931926), array(23.57670695), array(23.57417154), array(23.57170895), array(23.56931539), array(23.56698735), array(23.56472153), array(23.56251483), array(23.56036439), array(23.55826749), array(23.55622158), array(23.55422429), array(23.55227335), array(23.55036665), array(23.54850221), array(23.54667814), array(23.54489268), array(23.54314416), array(23.54143099), array(23.53975171), array(23.53810489), array(23.53648922), array(23.53490345), array(23.53334637), array(23.53181688), array(23.5303139), array(23.52883645), array(23.52738355), array(23.52595431), array(23.52454788), array(23.52316343), array(23.52180021), array(23.52045748), array(23.51913455), array(23.51783075), array(23.51654547), array(23.51527811), array(23.51402809), array(23.51279489), array(23.51157798), array(23.51037689), array(23.50919114), array(23.50802029), array(23.50686392), array(23.50572163), array(23.50459303), array(23.50347776), array(23.50237546), array(23.5012858), array(23.50020845), array(23.49914312), array(23.49808951), array(23.49704733), array(23.49601632), array(23.49499623), array(23.4939868), array(23.49298779), array(23.49199899), array(23.49102017), array(23.49005112), array(23.48909165), array(23.48814155), array(23.48720065), array(23.48626876), array(23.48534571), array(23.48443133), array(23.48352547), array(23.48262797), array(23.48173868), array(23.48085746), array(23.47998417), array(23.47911868), array(23.47826085), array(23.47741056), array(23.47656769), array(23.47573213), array(23.47490375), array(23.47408245)], 'Y_prediction_test': array([[0.05766936, 0.06108232, 0.05752942, ..., 0.05921585, 0.05889768,\n",
      "        0.05732865],\n",
      "       [0.0579415 , 0.06126301, 0.05784372, ..., 0.05948124, 0.05918515,\n",
      "        0.05765236],\n",
      "       [0.05764499, 0.06078055, 0.05755689, ..., 0.05908827, 0.05880969,\n",
      "        0.0573814 ],\n",
      "       ...,\n",
      "       [0.18322832, 0.19770294, 0.18616668, ..., 0.13319486, 0.13065238,\n",
      "        0.16967256],\n",
      "       [0.11222387, 0.1091177 , 0.11389299, ..., 0.09238482, 0.09215067,\n",
      "        0.10940422],\n",
      "       [0.14059325, 0.14644204, 0.14117386, ..., 0.1120637 , 0.11053456,\n",
      "        0.1327202 ]]), 'Y_prediction_train': array([[0.06112507, 0.05242858, 0.06095914, ..., 0.05920433, 0.05727111,\n",
      "        0.05952633],\n",
      "       [0.06132603, 0.05263054, 0.06121826, ..., 0.05950885, 0.05761756,\n",
      "        0.05982542],\n",
      "       [0.06089272, 0.05274846, 0.06078281, ..., 0.05917945, 0.05743315,\n",
      "        0.05947399],\n",
      "       ...,\n",
      "       [0.24555517, 0.15337092, 0.13609186, ..., 0.15761333, 0.20944422,\n",
      "        0.1580349 ],\n",
      "       [0.12570676, 0.11304961, 0.09291693, ..., 0.10405856, 0.12678468,\n",
      "        0.10328838],\n",
      "       [0.17168442, 0.13814148, 0.11394973, ..., 0.12631833, 0.1557197 ,\n",
      "        0.12626323]]), 'w': array([[-0.01216568, -0.0121986 , -0.01224316, ..., -0.00698434,\n",
      "        -0.00975083, -0.00727866],\n",
      "       [-0.01216511, -0.01219799, -0.01224247, ..., -0.00698039,\n",
      "        -0.00974715, -0.00727374],\n",
      "       [-0.01208251, -0.01210703, -0.01213411, ..., -0.00646792,\n",
      "        -0.00920346, -0.0064864 ],\n",
      "       ...,\n",
      "       [ 0.00232524,  0.00233154,  0.00234005, ...,  0.00133601,\n",
      "         0.00186434,  0.00139204],\n",
      "       [ 0.00232507,  0.00233136,  0.00233987, ...,  0.00133487,\n",
      "         0.00186358,  0.00139112],\n",
      "       [ 0.00232506,  0.00233135,  0.00233986, ...,  0.00133482,\n",
      "         0.00186354,  0.00139107]]), 'b': array([[-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483],\n",
      "       [-0.66822483]]), 'learning_rate': 0.01, 'num_iterations': 10000}\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_home = model(train_set_x_orig_home, train_set_y_home, test_set_x_orig_home, num_iterations=10000, learning_rate=0.01, print_cost=True)\n",
    "print(logistic_regression_model_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 41.588831\n",
      "Cost after iteration 100: 10.390756\n",
      "Cost after iteration 200: 10.355362\n",
      "Cost after iteration 300: 10.341120\n",
      "Cost after iteration 400: 10.332731\n",
      "Cost after iteration 500: 10.327055\n",
      "Cost after iteration 600: 10.322898\n",
      "Cost after iteration 700: 10.319686\n",
      "Cost after iteration 800: 10.317107\n",
      "Cost after iteration 900: 10.314973\n",
      "Cost after iteration 1000: 10.313168\n",
      "Cost after iteration 1100: 10.311613\n",
      "Cost after iteration 1200: 10.310255\n",
      "Cost after iteration 1300: 10.309053\n",
      "Cost after iteration 1400: 10.307980\n",
      "Cost after iteration 1500: 10.307014\n",
      "Cost after iteration 1600: 10.306137\n",
      "Cost after iteration 1700: 10.305336\n",
      "Cost after iteration 1800: 10.304601\n",
      "Cost after iteration 1900: 10.303922\n",
      "Cost after iteration 2000: 10.303293\n",
      "Cost after iteration 2100: 10.302708\n",
      "Cost after iteration 2200: 10.302160\n",
      "Cost after iteration 2300: 10.301648\n",
      "Cost after iteration 2400: 10.301165\n",
      "Cost after iteration 2500: 10.300711\n",
      "Cost after iteration 2600: 10.300281\n",
      "Cost after iteration 2700: 10.299873\n",
      "Cost after iteration 2800: 10.299486\n",
      "Cost after iteration 2900: 10.299117\n",
      "Cost after iteration 3000: 10.298766\n",
      "Cost after iteration 3100: 10.298429\n",
      "Cost after iteration 3200: 10.298108\n",
      "Cost after iteration 3300: 10.297799\n",
      "Cost after iteration 3400: 10.297503\n",
      "Cost after iteration 3500: 10.297218\n",
      "Cost after iteration 3600: 10.296944\n",
      "Cost after iteration 3700: 10.296679\n",
      "Cost after iteration 3800: 10.296424\n",
      "Cost after iteration 3900: 10.296177\n",
      "Cost after iteration 4000: 10.295938\n",
      "Cost after iteration 4100: 10.295706\n",
      "Cost after iteration 4200: 10.295482\n",
      "Cost after iteration 4300: 10.295264\n",
      "Cost after iteration 4400: 10.295053\n",
      "Cost after iteration 4500: 10.294847\n",
      "Cost after iteration 4600: 10.294647\n",
      "Cost after iteration 4700: 10.294452\n",
      "Cost after iteration 4800: 10.294262\n",
      "Cost after iteration 4900: 10.294077\n",
      "Cost after iteration 5000: 10.293896\n",
      "Cost after iteration 5100: 10.293720\n",
      "Cost after iteration 5200: 10.293547\n",
      "Cost after iteration 5300: 10.293379\n",
      "Cost after iteration 5400: 10.293214\n",
      "Cost after iteration 5500: 10.293053\n",
      "Cost after iteration 5600: 10.292895\n",
      "Cost after iteration 5700: 10.292740\n",
      "Cost after iteration 5800: 10.292589\n",
      "Cost after iteration 5900: 10.292440\n",
      "Cost after iteration 6000: 10.292294\n",
      "Cost after iteration 6100: 10.292151\n",
      "Cost after iteration 6200: 10.292011\n",
      "Cost after iteration 6300: 10.291873\n",
      "Cost after iteration 6400: 10.291737\n",
      "Cost after iteration 6500: 10.291604\n",
      "Cost after iteration 6600: 10.291473\n",
      "Cost after iteration 6700: 10.291344\n",
      "Cost after iteration 6800: 10.291218\n",
      "Cost after iteration 6900: 10.291093\n",
      "Cost after iteration 7000: 10.290970\n",
      "Cost after iteration 7100: 10.290850\n",
      "Cost after iteration 7200: 10.290731\n",
      "Cost after iteration 7300: 10.290613\n",
      "Cost after iteration 7400: 10.290498\n",
      "Cost after iteration 7500: 10.290384\n",
      "Cost after iteration 7600: 10.290272\n",
      "Cost after iteration 7700: 10.290161\n",
      "Cost after iteration 7800: 10.290052\n",
      "Cost after iteration 7900: 10.289944\n",
      "Cost after iteration 8000: 10.289838\n",
      "Cost after iteration 8100: 10.289733\n",
      "Cost after iteration 8200: 10.289629\n",
      "Cost after iteration 8300: 10.289527\n",
      "Cost after iteration 8400: 10.289426\n",
      "Cost after iteration 8500: 10.289326\n",
      "Cost after iteration 8600: 10.289228\n",
      "Cost after iteration 8700: 10.289130\n",
      "Cost after iteration 8800: 10.289034\n",
      "Cost after iteration 8900: 10.288939\n",
      "Cost after iteration 9000: 10.288845\n",
      "Cost after iteration 9100: 10.288752\n",
      "Cost after iteration 9200: 10.288660\n",
      "Cost after iteration 9300: 10.288570\n",
      "Cost after iteration 9400: 10.288480\n",
      "Cost after iteration 9500: 10.288391\n",
      "Cost after iteration 9600: 10.288303\n",
      "Cost after iteration 9700: 10.288216\n",
      "Cost after iteration 9800: 10.288130\n",
      "Cost after iteration 9900: 10.288045\n",
      "train accuracy: 99.51849595866827 %\n",
      "{'costs': [array(41.58883083), array(10.39075628), array(10.35536174), array(10.3411205), array(10.33273142), array(10.32705492), array(10.32289794), array(10.31968628), array(10.31710659), array(10.31497295), array(10.31316784), array(10.31161309), array(10.31025451), array(10.30905314), array(10.30798017), array(10.30701372), array(10.30613684), array(10.30533613), array(10.30460085), array(10.30392226), array(10.30329317), array(10.30270759), array(10.3021605), array(10.30164763), array(10.30116536), array(10.30071057), array(10.30028055), array(10.29987296), array(10.29948576), array(10.29911714), array(10.29876551), array(10.29842947), array(10.29810777), array(10.2977993), array(10.29750306), array(10.29721814), array(10.29694375), array(10.29667915), array(10.29642369), array(10.29617676), array(10.29593782), array(10.29570636), array(10.29548194), array(10.29526414), array(10.29505258), array(10.29484689), array(10.29464676), array(10.29445189), array(10.294262), array(10.29407684), array(10.29389617), array(10.29371976), array(10.29354741), array(10.29337893), array(10.29321414), array(10.29305287), array(10.29289498), array(10.29274031), array(10.29258872), array(10.29244009), array(10.29229429), array(10.29215122), array(10.29201077), array(10.29187283), array(10.29173732), array(10.29160413), array(10.29147319), array(10.29134442), array(10.29121774), array(10.29109307), array(10.29097036), array(10.29084954), array(10.29073053), array(10.2906133), array(10.29049777), array(10.2903839), array(10.29027164), array(10.29016094), array(10.29005174), array(10.28994402), array(10.28983773), array(10.28973282), array(10.28962926), array(10.28952701), array(10.28942604), array(10.28932631), array(10.28922779), array(10.28913045), array(10.28903426), array(10.28893919), array(10.28884522), array(10.28875231), array(10.28866044), array(10.28856959), array(10.28847973), array(10.28839084), array(10.28830291), array(10.28821589), array(10.28812979), array(10.28804457)], 'Y_prediction_test': array([[0.00227105, 0.00158983, 0.00290837, ..., 0.00585896, 0.0055769 ,\n",
      "        0.00482638],\n",
      "       [0.0022824 , 0.00136356, 0.00272211, ..., 0.00593447, 0.00552166,\n",
      "        0.00461801],\n",
      "       [0.00272333, 0.00208562, 0.00396898, ..., 0.0076934 , 0.00754544,\n",
      "        0.00674087],\n",
      "       ...,\n",
      "       [0.01999968, 0.02308115, 0.01459941, ..., 0.00981473, 0.00991277,\n",
      "        0.01064067],\n",
      "       [0.0083653 , 0.00937505, 0.00631912, ..., 0.00488802, 0.00487808,\n",
      "        0.00508488],\n",
      "       [0.01382634, 0.01655047, 0.01047475, ..., 0.00705904, 0.00711461,\n",
      "        0.00766922]]), 'Y_prediction_train': array([[0.00119062, 0.0011572 , 0.00458663, ..., 0.00502506, 0.00203797,\n",
      "        0.0045032 ],\n",
      "       [0.0009284 , 0.00087958, 0.00442309, ..., 0.00489533, 0.00180262,\n",
      "        0.00430556],\n",
      "       [0.0014075 , 0.0013257 , 0.00632383, ..., 0.0068842 , 0.00274618,\n",
      "        0.00626593],\n",
      "       ...,\n",
      "       [0.03080446, 0.03248142, 0.01107395, ..., 0.01056588, 0.01926484,\n",
      "        0.01116498],\n",
      "       [0.01337591, 0.01447467, 0.00524097, ..., 0.00508664, 0.00798192,\n",
      "        0.00525654],\n",
      "       [0.02319297, 0.0249244 , 0.00799542, ..., 0.00762001, 0.01385457,\n",
      "        0.00806455]]), 'w': array([[-0.02411833, -0.02370741, -0.02456067, ..., -0.01951339,\n",
      "        -0.02347778, -0.02192146],\n",
      "       [-0.02412347, -0.02370985, -0.02455249, ..., -0.01950512,\n",
      "        -0.02347065, -0.02190637],\n",
      "       [-0.02465113, -0.0240893 , -0.0233516 , ..., -0.01844425,\n",
      "        -0.02238977, -0.01993442],\n",
      "       ...,\n",
      "       [ 0.00495066,  0.00486681,  0.00504182, ...,  0.00400627,\n",
      "         0.00481944,  0.00449987],\n",
      "       [ 0.00495034,  0.0048663 ,  0.00504136, ...,  0.00400592,\n",
      "         0.00481933,  0.00449968],\n",
      "       [ 0.00495045,  0.0048662 ,  0.00504131, ...,  0.00400552,\n",
      "         0.00481914,  0.00449962]]), 'b': array([[-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953],\n",
      "       [-1.28484953]]), 'learning_rate': 0.01, 'num_iterations': 10000}\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_others = model(train_set_x_orig_others, train_set_y_others, test_set_x_orig_others, num_iterations=10000, learning_rate=0.01, print_cost=True)\n",
    "print(logistic_regression_model_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 41.588831\n",
      "Cost after iteration 100: 1.579854\n",
      "Cost after iteration 200: 1.443315\n",
      "Cost after iteration 300: 1.398774\n",
      "Cost after iteration 400: 1.376861\n",
      "Cost after iteration 500: 1.363914\n",
      "Cost after iteration 600: 1.355407\n",
      "Cost after iteration 700: 1.349410\n",
      "Cost after iteration 800: 1.344968\n",
      "Cost after iteration 900: 1.341552\n",
      "Cost after iteration 1000: 1.338849\n",
      "Cost after iteration 1100: 1.336660\n",
      "Cost after iteration 1200: 1.334853\n",
      "Cost after iteration 1300: 1.333339\n",
      "Cost after iteration 1400: 1.332053\n",
      "Cost after iteration 1500: 1.330947\n",
      "Cost after iteration 1600: 1.329988\n",
      "Cost after iteration 1700: 1.329149\n",
      "Cost after iteration 1800: 1.328409\n",
      "Cost after iteration 1900: 1.327752\n",
      "Cost after iteration 2000: 1.327165\n",
      "Cost after iteration 2100: 1.326638\n",
      "Cost after iteration 2200: 1.326162\n",
      "Cost after iteration 2300: 1.325730\n",
      "Cost after iteration 2400: 1.325337\n",
      "Cost after iteration 2500: 1.324978\n",
      "Cost after iteration 2600: 1.324649\n",
      "Cost after iteration 2700: 1.324346\n",
      "Cost after iteration 2800: 1.324066\n",
      "Cost after iteration 2900: 1.323807\n",
      "Cost after iteration 3000: 1.323567\n",
      "Cost after iteration 3100: 1.323343\n",
      "Cost after iteration 3200: 1.323135\n",
      "Cost after iteration 3300: 1.322941\n",
      "Cost after iteration 3400: 1.322758\n",
      "Cost after iteration 3500: 1.322587\n",
      "Cost after iteration 3600: 1.322427\n",
      "Cost after iteration 3700: 1.322276\n",
      "Cost after iteration 3800: 1.322133\n",
      "Cost after iteration 3900: 1.321999\n",
      "Cost after iteration 4000: 1.321872\n",
      "Cost after iteration 4100: 1.321751\n",
      "Cost after iteration 4200: 1.321637\n",
      "Cost after iteration 4300: 1.321529\n",
      "Cost after iteration 4400: 1.321426\n",
      "Cost after iteration 4500: 1.321328\n",
      "Cost after iteration 4600: 1.321235\n",
      "Cost after iteration 4700: 1.321146\n",
      "Cost after iteration 4800: 1.321061\n",
      "Cost after iteration 4900: 1.320980\n",
      "Cost after iteration 5000: 1.320902\n",
      "Cost after iteration 5100: 1.320828\n",
      "Cost after iteration 5200: 1.320757\n",
      "Cost after iteration 5300: 1.320689\n",
      "Cost after iteration 5400: 1.320624\n",
      "Cost after iteration 5500: 1.320561\n",
      "Cost after iteration 5600: 1.320501\n",
      "Cost after iteration 5700: 1.320443\n",
      "Cost after iteration 5800: 1.320387\n",
      "Cost after iteration 5900: 1.320334\n",
      "Cost after iteration 6000: 1.320282\n",
      "Cost after iteration 6100: 1.320232\n",
      "Cost after iteration 6200: 1.320184\n",
      "Cost after iteration 6300: 1.320138\n",
      "Cost after iteration 6400: 1.320093\n",
      "Cost after iteration 6500: 1.320050\n",
      "Cost after iteration 6600: 1.320008\n",
      "Cost after iteration 6700: 1.319967\n",
      "Cost after iteration 6800: 1.319928\n",
      "Cost after iteration 6900: 1.319890\n",
      "Cost after iteration 7000: 1.319854\n",
      "Cost after iteration 7100: 1.319818\n",
      "Cost after iteration 7200: 1.319784\n",
      "Cost after iteration 7300: 1.319750\n",
      "Cost after iteration 7400: 1.319718\n",
      "Cost after iteration 7500: 1.319687\n",
      "Cost after iteration 7600: 1.319656\n",
      "Cost after iteration 7700: 1.319626\n",
      "Cost after iteration 7800: 1.319597\n",
      "Cost after iteration 7900: 1.319569\n",
      "Cost after iteration 8000: 1.319542\n",
      "Cost after iteration 8100: 1.319516\n",
      "Cost after iteration 8200: 1.319490\n",
      "Cost after iteration 8300: 1.319465\n",
      "Cost after iteration 8400: 1.319440\n",
      "Cost after iteration 8500: 1.319417\n",
      "Cost after iteration 8600: 1.319393\n",
      "Cost after iteration 8700: 1.319371\n",
      "Cost after iteration 8800: 1.319349\n",
      "Cost after iteration 8900: 1.319327\n",
      "Cost after iteration 9000: 1.319306\n",
      "Cost after iteration 9100: 1.319286\n",
      "Cost after iteration 9200: 1.319266\n",
      "Cost after iteration 9300: 1.319246\n",
      "Cost after iteration 9400: 1.319227\n",
      "Cost after iteration 9500: 1.319209\n",
      "Cost after iteration 9600: 1.319190\n",
      "Cost after iteration 9700: 1.319173\n",
      "Cost after iteration 9800: 1.319155\n",
      "Cost after iteration 9900: 1.319138\n",
      "train accuracy: 99.76742524937042 %\n",
      "{'costs': [array(41.58883083), array(1.57985407), array(1.44331457), array(1.39877385), array(1.37686051), array(1.36391403), array(1.35540655), array(1.3494101), array(1.34496783), array(1.34155222), array(1.3388491), array(1.33665999), array(1.33485345), array(1.33333908), array(1.33205268), array(1.33094746), array(1.32998849), array(1.32914921), array(1.32840908), array(1.32775194), array(1.32716492), array(1.32663766), array(1.32616173), array(1.32573017), array(1.32533724), array(1.32497811), array(1.32464872), array(1.32434564), array(1.32406592), array(1.32380705), array(1.32356684), array(1.32334341), array(1.32313511), array(1.32294051), array(1.32275833), array(1.32258746), array(1.32242692), array(1.32227582), array(1.32213338), array(1.3219989), array(1.32187175), array(1.32175137), array(1.32163726), array(1.32152894), array(1.321426), array(1.32132807), array(1.32123481), array(1.32114588), array(1.32106102), array(1.32097996), array(1.32090245), array(1.32082828), array(1.32075724), array(1.32068914), array(1.32062381), array(1.3205611), array(1.32050085), array(1.32044292), array(1.32038719), array(1.32033355), array(1.32028187), array(1.32023205), array(1.32018401), array(1.32013764), array(1.32009288), array(1.32004963), array(1.32000782), array(1.3199674), array(1.31992828), array(1.31989041), array(1.31985374), array(1.31981821), array(1.31978376), array(1.31975036), array(1.31971795), array(1.3196865), array(1.31965596), array(1.3196263), array(1.31959747), array(1.31956945), array(1.3195422), array(1.3195157), array(1.31948991), array(1.3194648), array(1.31944036), array(1.31941655), array(1.31939334), array(1.31937073), array(1.31934869), array(1.31932719), array(1.31930621), array(1.31928575), array(1.31926577), array(1.31924627), array(1.31922723), array(1.31920863), array(1.31919045), array(1.31917269), array(1.31915532), array(1.31913835)], 'Y_prediction_test': array([[6.62195506e-05, 6.62195506e-05, 6.62195507e-05, ...,\n",
      "        6.62195507e-05, 6.62195508e-05, 6.62195510e-05],\n",
      "       [6.62195506e-05, 6.62195506e-05, 6.62195507e-05, ...,\n",
      "        6.62195507e-05, 6.62195508e-05, 6.62195510e-05],\n",
      "       [1.92062246e-04, 1.92062246e-04, 1.92062247e-04, ...,\n",
      "        1.92062246e-04, 1.92062247e-04, 1.92062247e-04],\n",
      "       ...,\n",
      "       [6.62754914e-05, 6.62754914e-05, 6.62754915e-05, ...,\n",
      "        6.62754915e-05, 6.62754917e-05, 6.62754919e-05],\n",
      "       [6.62195506e-05, 6.62195506e-05, 6.62195507e-05, ...,\n",
      "        6.62195507e-05, 6.62195508e-05, 6.62195510e-05],\n",
      "       [6.62195506e-05, 6.62195506e-05, 6.62195507e-05, ...,\n",
      "        6.62195507e-05, 6.62195508e-05, 6.62195510e-05]]), 'Y_prediction_train': array([[6.62195503e-05, 6.62195503e-05, 6.62195504e-05, ...,\n",
      "        6.62195506e-05, 6.62195503e-05, 6.62195505e-05],\n",
      "       [6.62195503e-05, 6.62195503e-05, 6.62195504e-05, ...,\n",
      "        6.62195506e-05, 6.62195503e-05, 6.62195505e-05],\n",
      "       [1.92062246e-04, 1.92062246e-04, 1.92062246e-04, ...,\n",
      "        1.92062246e-04, 1.92062245e-04, 1.92062246e-04],\n",
      "       ...,\n",
      "       [6.62754912e-05, 6.62754911e-05, 6.62754912e-05, ...,\n",
      "        6.62754915e-05, 6.62754911e-05, 6.62754913e-05],\n",
      "       [6.62195503e-05, 6.62195503e-05, 6.62195504e-05, ...,\n",
      "        6.62195506e-05, 6.62195503e-05, 6.62195505e-05],\n",
      "       [6.62195503e-05, 6.62195503e-05, 6.62195504e-05, ...,\n",
      "        6.62195506e-05, 6.62195503e-05, 6.62195505e-05]]), 'w': array([[-0.02335769, -0.02335769, -0.019755  , ..., -0.02335484,\n",
      "        -0.02335769, -0.02335769],\n",
      "       [-0.02335769, -0.02335769, -0.019755  , ..., -0.02335484,\n",
      "        -0.02335769, -0.02335769],\n",
      "       [-0.02335769, -0.02335769, -0.019755  , ..., -0.02335484,\n",
      "        -0.02335769, -0.02335769],\n",
      "       ...,\n",
      "       [ 0.0077859 ,  0.0077859 ,  0.006585  , ...,  0.00778494,\n",
      "         0.0077859 ,  0.0077859 ],\n",
      "       [ 0.0077859 ,  0.0077859 ,  0.006585  , ...,  0.00778494,\n",
      "         0.0077859 ,  0.0077859 ],\n",
      "       [ 0.0077859 ,  0.0077859 ,  0.006585  , ...,  0.00778494,\n",
      "         0.0077859 ,  0.0077859 ]]), 'b': array([[-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772],\n",
      "       [-2.71785772]]), 'learning_rate': 0.01, 'num_iterations': 10000}\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_school = model(train_set_x_orig_school, train_set_y_school, test_set_x_orig_school, num_iterations=10000, learning_rate=0.01, print_cost=True)\n",
    "print(logistic_regression_model_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 41.588831\n",
      "Cost after iteration 100: 9.374601\n",
      "Cost after iteration 200: 9.285743\n",
      "Cost after iteration 300: 9.255487\n",
      "Cost after iteration 400: 9.239976\n",
      "Cost after iteration 500: 9.230358\n",
      "Cost after iteration 600: 9.223682\n",
      "Cost after iteration 700: 9.218697\n",
      "Cost after iteration 800: 9.214779\n",
      "Cost after iteration 900: 9.211585\n",
      "Cost after iteration 1000: 9.208907\n",
      "Cost after iteration 1100: 9.206613\n",
      "Cost after iteration 1200: 9.204611\n",
      "Cost after iteration 1300: 9.202839\n",
      "Cost after iteration 1400: 9.201251\n",
      "Cost after iteration 1500: 9.199812\n",
      "Cost after iteration 1600: 9.198498\n",
      "Cost after iteration 1700: 9.197288\n",
      "Cost after iteration 1800: 9.196165\n",
      "Cost after iteration 1900: 9.195118\n",
      "Cost after iteration 2000: 9.194136\n",
      "Cost after iteration 2100: 9.193211\n",
      "Cost after iteration 2200: 9.192336\n",
      "Cost after iteration 2300: 9.191505\n",
      "Cost after iteration 2400: 9.190714\n",
      "Cost after iteration 2500: 9.189959\n",
      "Cost after iteration 2600: 9.189236\n",
      "Cost after iteration 2700: 9.188542\n",
      "Cost after iteration 2800: 9.187874\n",
      "Cost after iteration 2900: 9.187232\n",
      "Cost after iteration 3000: 9.186611\n",
      "Cost after iteration 3100: 9.186012\n",
      "Cost after iteration 3200: 9.185432\n",
      "Cost after iteration 3300: 9.184870\n",
      "Cost after iteration 3400: 9.184324\n",
      "Cost after iteration 3500: 9.183795\n",
      "Cost after iteration 3600: 9.183280\n",
      "Cost after iteration 3700: 9.182780\n",
      "Cost after iteration 3800: 9.182293\n",
      "Cost after iteration 3900: 9.181818\n",
      "Cost after iteration 4000: 9.181355\n",
      "Cost after iteration 4100: 9.180903\n",
      "Cost after iteration 4200: 9.180462\n",
      "Cost after iteration 4300: 9.180032\n",
      "Cost after iteration 4400: 9.179611\n",
      "Cost after iteration 4500: 9.179199\n",
      "Cost after iteration 4600: 9.178797\n",
      "Cost after iteration 4700: 9.178403\n",
      "Cost after iteration 4800: 9.178017\n",
      "Cost after iteration 4900: 9.177639\n",
      "Cost after iteration 5000: 9.177269\n",
      "Cost after iteration 5100: 9.176906\n",
      "Cost after iteration 5200: 9.176550\n",
      "Cost after iteration 5300: 9.176200\n",
      "Cost after iteration 5400: 9.175858\n",
      "Cost after iteration 5500: 9.175522\n",
      "Cost after iteration 5600: 9.175192\n",
      "Cost after iteration 5700: 9.174867\n",
      "Cost after iteration 5800: 9.174549\n",
      "Cost after iteration 5900: 9.174236\n",
      "Cost after iteration 6000: 9.173928\n",
      "Cost after iteration 6100: 9.173626\n",
      "Cost after iteration 6200: 9.173329\n",
      "Cost after iteration 6300: 9.173036\n",
      "Cost after iteration 6400: 9.172749\n",
      "Cost after iteration 6500: 9.172466\n",
      "Cost after iteration 6600: 9.172187\n",
      "Cost after iteration 6700: 9.171913\n",
      "Cost after iteration 6800: 9.171643\n",
      "Cost after iteration 6900: 9.171377\n",
      "Cost after iteration 7000: 9.171116\n",
      "Cost after iteration 7100: 9.170858\n",
      "Cost after iteration 7200: 9.170604\n",
      "Cost after iteration 7300: 9.170354\n",
      "Cost after iteration 7400: 9.170107\n",
      "Cost after iteration 7500: 9.169864\n",
      "Cost after iteration 7600: 9.169625\n",
      "Cost after iteration 7700: 9.169388\n",
      "Cost after iteration 7800: 9.169156\n",
      "Cost after iteration 7900: 9.168926\n",
      "Cost after iteration 8000: 9.168699\n",
      "Cost after iteration 8100: 9.168476\n",
      "Cost after iteration 8200: 9.168256\n",
      "Cost after iteration 8300: 9.168038\n",
      "Cost after iteration 8400: 9.167823\n",
      "Cost after iteration 8500: 9.167612\n",
      "Cost after iteration 8600: 9.167403\n",
      "Cost after iteration 8700: 9.167196\n",
      "Cost after iteration 8800: 9.166993\n",
      "Cost after iteration 8900: 9.166791\n",
      "Cost after iteration 9000: 9.166593\n",
      "Cost after iteration 9100: 9.166397\n",
      "Cost after iteration 9200: 9.166203\n",
      "Cost after iteration 9300: 9.166012\n",
      "Cost after iteration 9400: 9.165823\n",
      "Cost after iteration 9500: 9.165636\n",
      "Cost after iteration 9600: 9.165451\n",
      "Cost after iteration 9700: 9.165269\n",
      "Cost after iteration 9800: 9.165089\n",
      "Cost after iteration 9900: 9.164911\n",
      "train accuracy: 99.61686460974673 %\n",
      "{'costs': [array(41.58883083), array(9.37460137), array(9.28574311), array(9.25548749), array(9.23997614), array(9.23035786), array(9.22368249), array(9.21869672), array(9.21477905), array(9.21158509), array(9.20890736), array(9.2066126), array(9.20461083), array(9.20283882), array(9.20125075), array(9.1998125), array(9.19849813), array(9.19728756), array(9.19616499), array(9.19511781), array(9.19413586), array(9.19321082), array(9.19233586), array(9.19150529), array(9.19071434), array(9.18995897), array(9.18923575), array(9.18854173), array(9.18787439), array(9.18723152), array(9.18661119), array(9.18601172), array(9.18543161), array(9.18486954), array(9.18432434), array(9.18379494), array(9.1832804), array(9.18277986), array(9.18229255), array(9.18181775), array(9.18135483), array(9.18090319), array(9.18046228), array(9.18003162), array(9.17961072), array(9.17919917), array(9.17879656), array(9.17840253), array(9.17801673), array(9.17763883), array(9.17726853), array(9.17690554), array(9.17654961), array(9.17620047), array(9.17585788), array(9.17552163), array(9.1751915), array(9.17486729), array(9.17454881), array(9.17423587), array(9.17392831), array(9.17362596), array(9.17332866), array(9.17303627), array(9.17274864), array(9.17246564), array(9.17218714), array(9.17191301), array(9.17164314), array(9.17137741), array(9.17111571), array(9.17085794), array(9.170604), array(9.17035378), array(9.17010721), array(9.16986418), array(9.16962462), array(9.16938844), array(9.16915555), array(9.16892589), array(9.16869938), array(9.16847594), array(9.16825552), array(9.16803803), array(9.16782342), array(9.16761162), array(9.16740258), array(9.16719623), array(9.16699251), array(9.16679138), array(9.16659278), array(9.16639666), array(9.16620296), array(9.16601164), array(9.16582266), array(9.16563595), array(9.16545149), array(9.16526923), array(9.16508912), array(9.16491112)], 'Y_prediction_test': array([[7.03778950e-05, 5.42898679e-05, 7.58536819e-05, ...,\n",
      "        8.04044691e-05, 9.85340403e-05, 1.01866633e-04],\n",
      "       [7.03778950e-05, 5.42898679e-05, 7.58536819e-05, ...,\n",
      "        8.04044691e-05, 9.85340403e-05, 1.01866633e-04],\n",
      "       [7.03778950e-05, 5.42898679e-05, 7.58536819e-05, ...,\n",
      "        8.04044691e-05, 9.85340403e-05, 1.01866633e-04],\n",
      "       ...,\n",
      "       [9.64611791e-04, 7.92139384e-04, 1.01156026e-03, ...,\n",
      "        1.04828374e-03, 1.18792742e-03, 1.21312656e-03],\n",
      "       [7.03778950e-05, 5.42898679e-05, 7.58536819e-05, ...,\n",
      "        8.04044691e-05, 9.85340403e-05, 1.01866633e-04],\n",
      "       [7.03778950e-05, 5.42898679e-05, 7.58536819e-05, ...,\n",
      "        8.04044691e-05, 9.85340403e-05, 1.01866633e-04]]), 'Y_prediction_train': array([[5.27857840e-05, 9.68766148e-05, 6.87938762e-05, ...,\n",
      "        8.17283538e-05, 1.04231124e-04, 8.60720584e-05],\n",
      "       [5.27857840e-05, 9.68766148e-05, 6.87938762e-05, ...,\n",
      "        8.17283538e-05, 1.04231124e-04, 8.60720584e-05],\n",
      "       [5.27857840e-05, 9.68766148e-05, 6.87938762e-05, ...,\n",
      "        8.17283538e-05, 1.04231124e-04, 8.60720584e-05],\n",
      "       ...,\n",
      "       [7.70350779e-04, 1.17486957e-03, 9.48986857e-04, ...,\n",
      "        1.05863821e-03, 1.22875564e-03, 1.09356637e-03],\n",
      "       [5.27857840e-05, 9.68766148e-05, 6.87938762e-05, ...,\n",
      "        8.17283538e-05, 1.04231124e-04, 8.60720584e-05],\n",
      "       [5.27857840e-05, 9.68766148e-05, 6.87938762e-05, ...,\n",
      "        8.17283538e-05, 1.04231124e-04, 8.60720584e-05]]), 'w': array([[-0.04001342, -0.04001342, -0.04001342, ..., -0.02779242,\n",
      "        -0.04001342, -0.04001342],\n",
      "       [-0.04001085, -0.04001085, -0.04001085, ..., -0.02778754,\n",
      "        -0.04001085, -0.04001085],\n",
      "       [-0.03969703, -0.03969703, -0.03969703, ..., -0.02716813,\n",
      "        -0.03969703, -0.03969703],\n",
      "       ...,\n",
      "       [ 0.00886142,  0.00886142,  0.00886142, ...,  0.00615498,\n",
      "         0.00886142,  0.00886142],\n",
      "       [ 0.00886095,  0.00886095,  0.00886095, ...,  0.00615469,\n",
      "         0.00886095,  0.00886095],\n",
      "       [ 0.00886073,  0.00886073,  0.00886073, ...,  0.00615455,\n",
      "         0.00886073,  0.00886073]]), 'b': array([[-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445],\n",
      "       [-1.6614445]]), 'learning_rate': 0.01, 'num_iterations': 10000}\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model_work = model(train_set_x_orig_work, train_set_y_work, test_set_x_orig_work, num_iterations=10000, learning_rate=0.01, print_cost=True)\n",
    "print(logistic_regression_model_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\source_data\\synthetic_contacts_2021.csv\")\n",
    "data=data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr=logistic_regression_model_all[\"Y_prediction_train\"]\n",
    "Yt=logistic_regression_model_all[\"Y_prediction_test\"]\n",
    "m=np.max(train_set_y_m_all)\n",
    "Yr=Yr*m\n",
    "Yt=Yt*m\n",
    "\n",
    "\n",
    "C=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_train_all.xlsx') as writer:\n",
    "    for i in range(120):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                C[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(C).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*i)][0]}', index=False) \n",
    "\n",
    "N=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_test_all.xlsx') as writer:\n",
    "    for i in range(30):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                N[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(N).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*(i+120))][0]}', index=False) \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr=logistic_regression_model_home[\"Y_prediction_train\"]\n",
    "Yt=logistic_regression_model_home[\"Y_prediction_test\"]\n",
    "m=np.max(train_set_y_m_home)\n",
    "Yr=Yr*m\n",
    "Yt=Yt*m\n",
    "\n",
    "\n",
    "C=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_train_home.xlsx') as writer:\n",
    "    for i in range(120):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                C[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(C).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*i)][0]}', index=False) \n",
    "\n",
    "N=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_test_home.xlsx') as writer:\n",
    "    for i in range(30):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                N[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(N).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*(i+120))][0]}', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr=logistic_regression_model_others[\"Y_prediction_train\"]\n",
    "Yt=logistic_regression_model_others[\"Y_prediction_test\"]\n",
    "m=np.max(train_set_y_m_others)\n",
    "Yr=Yr*m\n",
    "Yt=Yt*m\n",
    "\n",
    "\n",
    "C=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_train_others.xlsx') as writer:\n",
    "    for i in range(120):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                C[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(C).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*i)][0]}', index=False) \n",
    "\n",
    "N=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_test_others.xlsx') as writer:\n",
    "    for i in range(30):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                N[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(N).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*(i+120))][0]}', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr=logistic_regression_model_school[\"Y_prediction_train\"]\n",
    "Yt=logistic_regression_model_school[\"Y_prediction_test\"]\n",
    "m=np.max(train_set_y_m_school)\n",
    "Yr=Yr*m\n",
    "Yt=Yt*m\n",
    "\n",
    "\n",
    "C=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_train_school.xlsx') as writer:\n",
    "    for i in range(120):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                C[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(C).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*i)][0]}', index=False) \n",
    "\n",
    "N=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_test_school.xlsx') as writer:\n",
    "    for i in range(30):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                N[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(N).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*(i+120))][0]}', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr=logistic_regression_model_work[\"Y_prediction_train\"]\n",
    "Yt=logistic_regression_model_work[\"Y_prediction_test\"]\n",
    "m=np.max(train_set_y_m_work)\n",
    "Yr=Yr*m\n",
    "Yt=Yt*m\n",
    "\n",
    "\n",
    "C=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_train_work.xlsx') as writer:\n",
    "    for i in range(120):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                C[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(C).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*i)][0]}', index=False) \n",
    "\n",
    "N=np.zeros((16,16))\n",
    "with pd.ExcelWriter(r'E:\\Hraf\\S8\\Projet à Enjeux\\Projet Enjeux\\matrices de contact predeted\\contact_predeted_test_work.xlsx') as writer:\n",
    "    for i in range(30):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                N[j][k]=Yr[k+16*j][i]\n",
    "                pd.DataFrame(N).to_excel(writer, sheet_name=f'matrice_{data[((256-(16*(1+10)))+10)+256*(5*(i+120))][0]}', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
